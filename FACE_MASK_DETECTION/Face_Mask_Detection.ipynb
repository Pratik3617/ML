{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ccac2b-f9ac-456b-ac78-453f2e33e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 17:03:31.180268: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-11 17:03:31.197597: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739273611.218434 2693032 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739273611.224641 2693032 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-11 17:03:31.246774: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1739273614.371010 2693032 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16173 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:51:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.333\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e2879-e290-414d-8566-0ea6b67a641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511cf9b-002b-4807-82b4-74b76286978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['with_mask', 'without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc4660-a74e-4786-bcb4-7429ee63d080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for category in categories:\n",
    "    path = os.path.join('train',category)\n",
    "    for file in os.listdir(path):\n",
    "        img_path = os.path.join(path,file)\n",
    "        label = categories.index(category)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img,(224,224))\n",
    "        data.append([img,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e59703-0d39-4b28-9c96-59778d63215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a20d8-d651-4374-9c84-f8d2ea75d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd58395-1a13-449b-b24a-4a35c11870c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)/ 255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d1476a-e959-42b5-b657-3eccfaf142b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c222b-8062-4f24-8af9-69af89df507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c70b2-1876-4413-985e-7423e36a88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cec9f-597d-44ac-9469-f12e17738ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d573e9-60a2-417f-a515-a8815d2fac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be2c45-066a-4449-abb6-d9b28a4d62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())  # Convert feature maps to 1D\n",
    "model.add(Dense(256, activation='relu'))  # Optional extra layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b18d11-bc6f-4e26-8967-e102191a63aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ebd254-234a-43ad-b14c-6e65291fb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459befa-b74f-4235-b0f8-e9da63706d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2742e3-0fab-47be-b824-7bd8ccf442f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e960816-12eb-4c6c-a993-90e963e462f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05cfc4-ea95-4145-a529-2110d5013ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ef5bc2-980e-4da2-8800-44c9798783d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739273616.166720 2693032 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16173 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:51:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open(\"model.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e012c9e-f38e-40d9-b098-93e5cd26e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_face_mask(img, model):\n",
    "    img = img.astype(\"float32\") / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    y_pred = model.predict(img)\n",
    "    confidence = y_pred[0][0]  # Get prediction confidence\n",
    "\n",
    "    print(f\"[DEBUG] Prediction: {y_pred} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "    if confidence > 0.5:\n",
    "        return \"Without Mask\", confidence\n",
    "    else:\n",
    "        return \"With Mask\", 1 - confidence  # Adjust confidence for \"With Mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31887abe-f3e1-446a-a511-399a386c5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write in video\n",
    "def draw_label(img,text,pos,bg_color):\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, cv2.FILLED)\n",
    "\n",
    "    end_x = pos[0] + text_size[0][0] + 2\n",
    "    end_y = pos[1] + text_size[0][1] - 2\n",
    "\n",
    "    cv2.rectangle(img,pos,(end_x,end_y),bg_color,cv2.FILLED)\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),1,cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb3ef51-1116-4792-8818-159c2516ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for rectangle around face\n",
    "import cv2\n",
    "haar = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "def detect_face(img):\n",
    "    coordindates = haar.detectMultiScale(img)\n",
    "    return coordindates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc282c73-3b4f-4a7d-90e7-b0a2c5c6e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n",
      "[INFO] No faces detected in this frame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739273641.271209 2949434 service.cc:148] XLA service 0x73269400a290 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739273641.271292 2949434 service.cc:156]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2025-02-11 17:04:01.298085: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1739273641.384166 2949434 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739273642.389431 2949434 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Prediction: [[0.7268591]] (Confidence: 0.73)\n",
      "[DEBUG] Face detected at: x=305, y=35, w=70, h=70 - Prediction: ('Without Mask', 0.7268591)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Can't convert object to 'str' for 'text'\n>  - Can't convert object to 'str' for 'text'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Run detection on a video file\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdetect_mask_in_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest2.mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m, in \u001b[0;36mdetect_mask_in_video\u001b[0;34m(video_path, model)\u001b[0m\n\u001b[1;32m     36\u001b[0m     color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith Mask\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[1;32m     37\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x, y), (x\u001b[38;5;241m+\u001b[39mw, y\u001b[38;5;241m+\u001b[39mh), color, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mputText\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFONT_HERSHEY_SIMPLEX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMask Detection\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'putText'\n> Overload resolution failed:\n>  - Can't convert object to 'str' for 'text'\n>  - Can't convert object to 'str' for 'text'\n"
     ]
    }
   ],
   "source": [
    "# Function to detect mask in video\n",
    "def detect_mask_in_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=7) \n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"[INFO] No faces detected in this frame.\")\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Ignore small detections (likely false positives)\n",
    "            if w < 50 or h < 50:\n",
    "                print(f\"[INFO] Ignoring small detection: x={x}, y={y}, w={w}, h={h}\")\n",
    "                continue  \n",
    "\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "\n",
    "            prediction = predict_face_mask(face, model)\n",
    "\n",
    "            print(f\"[DEBUG] Face detected at: x={x}, y={y}, w={w}, h={h} - Prediction: {prediction}\")\n",
    "\n",
    "            color = (0, 255, 0) if prediction == \"With Mask\" else (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, prediction, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Mask Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    if output_path:\n",
    "        out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run detection on a video file\n",
    "detect_mask_in_video('test2.mp4', model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc93ccd-c2eb-436f-bfc0-6f28c835f57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_mask_with_webcam(model):\n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "    haar = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"[ERROR] Failed to capture image from webcam.\")\n",
    "            break\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"[INFO] No faces detected.\")\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "\n",
    "            prediction, confidence = predict_face_mask(face, model)\n",
    "\n",
    "            # Debugging: Print face coordinates and confidence score\n",
    "            print(f\"[DEBUG] Face at x={x}, y={y}, w={w}, h={h} - {prediction} ({confidence:.2f})\")\n",
    "\n",
    "            color = (0, 255, 0) if prediction == \"With Mask\" else (0, 0, 255)\n",
    "            label = f\"{prediction} ({confidence:.2f})\"  # Add confidence score\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Mask Detection - Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run mask detection from webcam\n",
    "detect_mask_with_webcam(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c17dd-2a71-4402-b694-d2d5dd743ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03b157-7e9b-4acf-97ca-21d712f032e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    print(ret, frame)\n",
    "\n",
    "    img = cv2.resize(frame,(224,224))\n",
    "    y_pred = predict_face_mask(img)\n",
    "    coords = detect_face(cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY))\n",
    "\n",
    "    for x,y,h,w in coords:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "    if(y_pred==\"With Mask\"):\n",
    "        draw_label(frame,\"With Mask\",(10,10),(0,255,0))\n",
    "    else:\n",
    "        draw_label(frame,\"Without Mask\",(10,10),(0,0,255))\n",
    "    cv2.imshow(\"window\",frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7bee7-d0a4-4c96-8037-34f548e64100",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = cv2.imread('mask.jpg')\n",
    "sample1 = cv2.resize(sample1,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13809b21-b338-4d9e-b306-fc0ae8dedba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample1,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09578357-977b-4ee3-a468-c580fdd69234",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample2 = cv2.imread('without_mask.jpg')\n",
    "sample2 = cv2.resize(sample2,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be8a75-9847-4ecb-bb54-d8fbfc63be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71296c-81bc-4101-b01e-1e9c352e98f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample3 = cv2.imread('test11.jpg')\n",
    "sample3 = cv2.resize(sample3,(224,224))\n",
    "sample4 = cv2.imread('test12.jpg')\n",
    "sample4 = cv2.resize(sample4,(224,224))\n",
    "sample5 = cv2.imread('test13.jpg')\n",
    "sample5 = cv2.resize(sample5,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4373d7-aea5-4cb9-b2c6-e1f2ebccb69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample6 = cv2.imread('test21.jpg')\n",
    "sample6 = cv2.resize(sample6,(224,224))\n",
    "sample7 = cv2.imread('test22.jpg')\n",
    "sample7 = cv2.resize(sample6,(224,224))\n",
    "sample8 = cv2.imread('test23.jpg')\n",
    "sample8 = cv2.resize(sample6,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87df449-6660-47af-af99-28e1ce327f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e594e9-9b42-459f-9d33-9d6fa4bdf0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076abea-93c4-4ede-be03-0ad7243b037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608936d-85bf-4b6d-a77e-728c69464df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987e047-14a5-48d4-ad0e-0cd2537ad522",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4893f-5217-4ce1-809f-9c71a69e274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_face_mask(sample8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e97496-86b4-4ec0-8a08-1cafe2b5fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def predict_face_mask(img, model):\n",
    "    img = img.astype(\"float32\") / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    y_pred = model.predict(img)\n",
    "    confidence = y_pred[0][0]  # Get prediction confidence\n",
    "\n",
    "    print(f\"[DEBUG] Prediction: {y_pred} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "    if confidence > 0.5:\n",
    "        return \"Without Mask\", confidence\n",
    "    else:\n",
    "        return \"With Mask\", 1 - confidence  # Adjust confidence for \"With Mask\"\n",
    "\n",
    "def detect_mask_with_webcam(model):\n",
    "    cap = cv2.VideoCapture(0)  # Open webcam\n",
    "    haar = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"[ERROR] Failed to capture image from webcam.\")\n",
    "            break\n",
    "\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = haar.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            print(\"[INFO] No faces detected.\")\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "\n",
    "            prediction, confidence = predict_face_mask(face, model)\n",
    "\n",
    "            # Debugging: Print face coordinates and confidence score\n",
    "            print(f\"[DEBUG] Face at x={x}, y={y}, w={w}, h={h} - {prediction} ({confidence:.2f})\")\n",
    "\n",
    "            color = (0, 255, 0) if prediction == \"With Mask\" else (0, 0, 255)\n",
    "            label = f\"{prediction} ({confidence:.2f})\"  # Add confidence score\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Mask Detection - Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run mask detection from webcam\n",
    "detect_mask_with_webcam(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiT",
   "language": "python",
   "name": "dit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
