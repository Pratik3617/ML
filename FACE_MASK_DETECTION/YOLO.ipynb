{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3500d-9455-46af-a97d-eb473150d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.333\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6916951f-136e-445b-9ea4-edf408152217",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1c0f9-f506-423b-8b80-77a2f7fcc324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv5 model for face detection\n",
    "yolo_face = YOLO(\"yolov5s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f68e8-eaa9-4435-959a-9283c33b40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories\n",
    "categories = ['with_mask', 'without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d15fcd-9ad2-48f4-8e78-c1e6b35f831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8070283-6cbe-491d-b172-d43eb9b5cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "data = []\n",
    "for category in categories:\n",
    "    path = os.path.join('train', category)\n",
    "    label = categories.index(category)  # 0 for with_mask, 1 for without_mask\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        img_path = os.path.join(path, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        data.append([img, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a64e52-a327-4ed6-aa90-ccefcf352160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data to mix classes\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57eddbe-69f1-4856-b947-939b2fda6411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input and labels\n",
    "X = []\n",
    "y = []\n",
    "for features, label in data:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c950ed-c0e9-483c-86e8-1ba7cacfa8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X) / 255.0  # Normalize images\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48feed27-1cff-41f2-8cf8-3d7d828129ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d0b10f-e19a-4620-abaf-28d0efcb6e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply augmentation only to training set\n",
    "train_generator = data_gen.flow(X_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac92eb9-f167-4155-9cd5-b81500155737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(224, 224, 3)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2e789-eab0-419c-8f2c-a0dd9890251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b1856-3e08-4387-93b7-2b13a1903a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b3808-afab-4ccc-a487-bf9a0f070354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with augmentation\n",
    "model.fit(train_dataset, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c0c7a-ff43-4070-b7a3-8373b360200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('yolo_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83631da4-79de-443f-962b-c8c2a0232420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict mask status\n",
    "def predict_face_mask(img):\n",
    "    img = img / 255.0  # Normalize\n",
    "    y_pred = model.predict(img.reshape(1, 224, 224, 3))\n",
    "    return \"Without Mask\" if y_pred[0][0] > 0.5 else \"With Mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c084da-a6be-40e5-b780-d92c59dae724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "sample1 = cv2.imread('mask.jpg')\n",
    "sample1 = cv2.resize(sample1, (224, 224))\n",
    "\n",
    "sample2 = cv2.imread('without_mask.jpg')\n",
    "sample2 = cv2.resize(sample2, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483faf85-21bb-40ea-b0c6-814beda5d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample1 Prediction:\", predict_face_mask(sample1))\n",
    "print(\"Sample2 Prediction:\", predict_face_mask(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc80110-55b6-479d-8175-0638951c2df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection with YOLO\n",
    "def detect_faces(img):\n",
    "    results = yolo_face(img)  # Run YOLO detection\n",
    "    faces = []\n",
    "    for result in results:\n",
    "        for box in result.boxes.xyxy:  # Get bounding boxes\n",
    "            x, y, x2, y2 = map(int, box)\n",
    "            faces.append((x, y, x2 - x, y2 - y))  # Convert to (x, y, w, h)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cce287-41e7-4850-94f9-362b6e253d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw label function\n",
    "def draw_label(img, text, pos, bg_color):\n",
    "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, cv2.FILLED)[0]\n",
    "    end_x, end_y = pos[0] + text_size[0] + 2, pos[1] - text_size[1] - 2\n",
    "    cv2.rectangle(img, pos, (end_x, end_y), bg_color, cv2.FILLED)\n",
    "    cv2.putText(img, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99172143-2aad-4f3a-ad69-c5d80f90e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live webcam detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    faces = detect_faces(frame)\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (224, 224)) / 255.0  # Normalize\n",
    "        prediction = predict_face_mask(face)\n",
    "\n",
    "        color = (0, 255, 0) if prediction == \"With Mask\" else (0, 0, 255)\n",
    "        draw_label(frame, prediction, (x, y-10), color)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "    cv2.imshow(\"Mask Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1365635e-c0db-4692-bb1c-864d631173d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiT",
   "language": "python",
   "name": "dit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
